{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "main.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lennertjansen/nlp2/blob/master/project1/datageneration.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lhUTSCXSzOws",
        "colab_type": "text"
      },
      "source": [
        "Mount notebook to drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tYoYPc-FzWeA",
        "colab_type": "code",
        "outputId": "685317d6-d34f-4d3f-b2e1-63ecfe171ef1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ltKVMbGoUwcU",
        "colab_type": "code",
        "outputId": "f3e42e51-96a8-4bbb-f876-40ec8636c26c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "%cd drive/My\\ Drive/nlp2/code\n",
        "!ls"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/.shortcut-targets-by-id/1QXwx2THcNLhcOFb0uOdUp12fL_lxsei0/nlp2/code\n",
            "'Colab Tutorial'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bWcmAuhNQCWA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YVtzYYRxVDC1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        " To generate our dataset, we need a few things:\n",
        " 1. Grammar rules (So a PCFG) with all grammar rules\n",
        " 2. Lexical rules (a vocabulary)\n",
        " 3. A generation mechanism, that probabilistically samples how to fill in each instance, and that can stop. Should also be able to give metadata to each datapoint \n",
        " 4. Potentially a function that checks if the grammar is correct (could also be done by hand)\n",
        " 5. A translation function, that converts each generated sample into its correct interpretation. This needs interpretation rules, and a lookup table\n",
        " Notes:\n",
        " - Use nested dict for lookup table\n",
        " \"\"\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "co6l9-Qn5y9L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class PCFG_rule:\n",
        "  def __init__(self, lhs, rhs, prob):\n",
        "    self.lhs = lhs\n",
        "    self.rhs = rhs\n",
        "    self.prob = prob\n",
        "  \n",
        "  def __str__(self):\n",
        "    if isinstance(self.rhs, list):\n",
        "      return (\"({}) {} --> {}\".format( self.prob, ' '.join(self.lhs), ' '.join(self.rhs) ))\n",
        "    else:\n",
        "      return (\"({}) {} --> {}\".format( self.prob, ' '.join(self.lhs), self.rhs ))\n",
        "\n",
        "class PCFG:\n",
        "  def __init__(self):\n",
        "    self.rules = {}\n",
        "\n",
        "  def add(self, lhs, rhs, prob):\n",
        "    rule = PCFG_rule(lhs, rhs, prob)\n",
        "    if isinstance(lhs,list):\n",
        "      lhs = tuple(lhs) # Tuple is hashable\n",
        "    if lhs in self.rules.keys():\n",
        "      self.rules[lhs].append(rule)\n",
        "    else:\n",
        "      self.rules[lhs] = [rule]\n",
        "\n",
        "  def select(self, lhs):\n",
        "    lhs = tuple(lhs)\n",
        "    return self.rules[lhs]\n",
        "\n",
        "  def sample(self, lhs):\n",
        "    # print(lhs, len(lhs))\n",
        "    assert not ((isinstance(lhs, list) or isinstance(lhs, tuple)) and len(lhs)>1), \"Only single words or non-terminals can be filled in.\"\n",
        "    if isinstance(lhs, list):\n",
        "      lhs = tuple(lhs)\n",
        "    # print(\"Sampling for \", lhs)\n",
        "    if not self.rules.get(lhs):\n",
        "      return lhs, True\n",
        "    rules = self.rules.get(lhs)\n",
        "    # print(rules)\n",
        "    probs = [rule.prob for rule in rules]\n",
        "    # print(\"probabilities: \", probs)\n",
        "    number_of_options = len(rules)\n",
        "\n",
        "    choice_index = np.random.choice(a = number_of_options, p = probs)\n",
        "    # print(\"Selected option: \", rules[choice_index].rhs)\n",
        "    return rules[choice_index].rhs, False\n",
        "\n",
        "  def generate(self, sequence):\n",
        "    # print(\"Generating for starting sequence \", sequence)\n",
        "    finished = False\n",
        "    while not finished:\n",
        "      finished_list = [False]*len(sequence)\n",
        "      new_sequence = []\n",
        "      for i, lhs in enumerate(sequence):\n",
        "        rhs, finished_list[i] = ruleset.sample(lhs)\n",
        "        if isinstance(rhs, list):\n",
        "          new_sequence.extend(rhs)\n",
        "        elif isinstance(rhs, str):\n",
        "          new_sequence.append(rhs)\n",
        "      sequence = new_sequence\n",
        "      # print(\"New sequence: \", sequence)\n",
        "      if all(finished_list):\n",
        "        finished = True\n",
        "    return sequence\n",
        "      \n",
        "\n",
        "\n",
        "  def __str__(self):\n",
        "    string = ''\n",
        "    for key in self.rules.keys():\n",
        "      for item in self.rules[key]:\n",
        "        # print(item)\n",
        "        string += item.__str__()\n",
        "        # print(item.__str__())\n",
        "        string += '\\n'\n",
        "    return string"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2L_twi8T4Im0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "e22db1c9-0da6-432f-f4f5-a16d7ebacc69"
      },
      "source": [
        "# 1: grammar rules. We will encode this in an array? dict? tuple? \n",
        "# dict - tuple: prob (where tuple - [lhs , rhs] for lhs --> rhs)\n",
        "# Better option: python array, with [lhs, rhs, prob] for each cfg rule\n",
        "# Where lhs is a list of each character in lhs, and rhs same for rhs\n",
        "# Actually, best option is to use a dict. Since we will be generating, the lhs should be the key.\n",
        "# So: dict of {lhs: [[rhs1, prob1], [rhs2, prob2]]}\n",
        "# rule = PCFG_rule()\n",
        "ruleset = PCFG()\n",
        "\n",
        "# Non-terminal rules:\n",
        "\n",
        "lhs = 'S' # valid sequence is an object: S --> O\n",
        "rhs = ['O']\n",
        "prob = 1\n",
        "ruleset.add(lhs, rhs, prob)\n",
        "\n",
        "lhs = 'O' # O --> A O\n",
        "rhs = ['A', 'O']\n",
        "prob = 0.25\n",
        "ruleset.add(lhs, rhs, prob)\n",
        "\n",
        "lhs = 'O' # O --> A T O\n",
        "rhs = ['A', 'T', 'O']\n",
        "prob = 0.1\n",
        "ruleset.add(lhs, rhs, prob)\n",
        "\n",
        "# lhs = 'O' # O --> N O\n",
        "# rhs = ['N', 'O']\n",
        "# prob = 0.05\n",
        "# ruleset.add(lhs, rhs, prob)\n",
        "\n",
        "lhs = 'A' # A --> A N\n",
        "\n",
        "lhs = 'O' # O --> O & O\n",
        "rhs = ['O', '&', 'O']\n",
        "prob = 0.1\n",
        "ruleset.add(lhs, rhs, prob)\n",
        "\n",
        "\n",
        "lhs = 'T' # T --> W H\n",
        "rhs = ['W', 'H']\n",
        "prob = 1\n",
        "ruleset.add(lhs, rhs, prob)\n",
        "\n",
        "# lhs = ['A', 'O'] # A O --> A O & O\n",
        "# rhs = ['A', 'O', '&', 'O']\n",
        "# prob = 0.4\n",
        "# ruleset.add(lhs, rhs, prob)\n",
        "\n",
        "\n",
        "print('All non-terminal rules: \\n', ruleset)\n",
        "\n",
        "# Problem:\n",
        "# cut tomato and cut steak should be a valid S\n",
        "# S --> A O & A O \n",
        "# These should also be possibly nested in another action, so\n",
        "# A O --> A A O & A O\n",
        "# This reduces to O --> A O & A O, which reduces to O --> O & O \n",
        "# Above is true since O --> A O\n",
        "# O --> O & O should not be possible (why not?)\n",
        "# This causes line 47 to be ambiguous - unless we use a 'then' word in addition to and\n",
        "# 'then' would indicate the end of the scope of an action, where 'and' would include the next object"
      ],
      "execution_count": 133,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "All non-terminal rules: \n",
            " (1) S --> O\n",
            "(0.25) O --> A O\n",
            "(0.1) O --> A T O\n",
            "(0.05) O --> N O\n",
            "(0.1) O --> O & O\n",
            "(1) T --> W H\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E6V5z0pV7iQd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 476
        },
        "outputId": "6e99f3a5-ba5a-480e-c220-d7e08ff300b8"
      },
      "source": [
        "# All lexical rules:\n",
        "\n",
        "# Object rules:\n",
        "lhs = 'O'\n",
        "objects = ['tomato', 'steak', 'onion', 'potato', 'chicken', 'pork']\n",
        "obj_probs = [0.1, 0.1, 0.1, 0.1, 0.05, 0.05] # We don't like chicken and pork\n",
        "# Note: will the eventual model be largely carnivorous or herbivorous?\n",
        "for rhs, prob in zip(objects, obj_probs):\n",
        "  ruleset.add(lhs, rhs, prob)\n",
        "# print(ruleset)\n",
        "\n",
        "# Action rules:\n",
        "lhs = 'A'\n",
        "actions = ['cut', 'fry', 'grill', 'clean', 'boil']\n",
        "act_probs = [0.3, 0.2, 0.2, 0.2, 0.1]\n",
        "for rhs, prob in zip(actions, act_probs):\n",
        "  ruleset.add(lhs, rhs, prob)\n",
        "\n",
        "# Number rules:\n",
        "lhs = 'N'\n",
        "numbers = ['one', 'two', 'three', 'four', 'five']\n",
        "num_probs = [0.4, 0.3, 0.1, 0.1, 0.1]\n",
        "for rhs, prob in zip(numbers, num_probs):\n",
        "  ruleset.add(lhs, rhs, prob)\n",
        "\n",
        "# Connective rules:\n",
        "lhs = '&'\n",
        "connectives = ['and', 'after', 'then']\n",
        "conn_probs = [0.4, 0.2, 0.4]\n",
        "for rhs, prob in zip(connectives, conn_probs):\n",
        "  ruleset.add(lhs, rhs, prob)\n",
        "\n",
        "# With rule:\n",
        "lhs = 'W'\n",
        "w = ['with']\n",
        "w_prob = 1\n",
        "ruleset.add(lhs, w, w_prob)\n",
        "\n",
        "# Tool rules:\n",
        "# lhs = ['H']\n",
        "# tools = ['vegknife', 'meatknife', 'fryingpan', 'grill', 'boil', 'season']\n",
        "# conn_probs = [0., 0.2, 0.4]\n",
        "# for rhs, prob in zip(connectives, conn_probs):\n",
        "#   ruleset.add(lhs, rhs, prob)\n",
        "# How do we make sure these only appear in the correct context?\n",
        "# Probably easiest to filter the wrong ones out?\n",
        "# Or use context based rules for generation. Or even substitute actions as 'action with tool'\n",
        "# strings? Probably context based rules is best, based on intuition.\n",
        "# Probably we should implement the tools in a different function than in the PCFG\n",
        "\n",
        "print(ruleset)"
      ],
      "execution_count": 134,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1) S --> O\n",
            "(0.25) O --> A O\n",
            "(0.1) O --> A T O\n",
            "(0.05) O --> N O\n",
            "(0.1) O --> O & O\n",
            "(0.1) O --> tomato\n",
            "(0.1) O --> steak\n",
            "(0.1) O --> onion\n",
            "(0.1) O --> potato\n",
            "(0.05) O --> chicken\n",
            "(0.05) O --> pork\n",
            "(1) T --> W H\n",
            "(0.3) A --> cut\n",
            "(0.2) A --> fry\n",
            "(0.2) A --> grill\n",
            "(0.2) A --> clean\n",
            "(0.1) A --> boil\n",
            "(0.4) N --> one\n",
            "(0.3) N --> two\n",
            "(0.1) N --> three\n",
            "(0.1) N --> four\n",
            "(0.1) N --> five\n",
            "(0.4) & --> and\n",
            "(0.2) & --> after\n",
            "(0.4) & --> then\n",
            "(1) W --> with\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1KRfnL0lGfNL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "outputId": "1d51166b-b8d5-4bb1-a58a-c86e66374aac"
      },
      "source": [
        "# Now, part two: generation\n",
        "# We will generate grammatically correct sequences, where we only leave the tools not filled in.\n",
        "# We always start from an S, and then randomly pick a way to fill it in, recursively\n",
        "for i in range(20):\n",
        "  sequence = ['S']\n",
        "  sequence = ruleset.generate(sequence)\n",
        "  print(\"Sequence {}: {}\".format(i,sequence))"
      ],
      "execution_count": 135,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sequence 0: ['onion', 'then', 'onion']\n",
            "Sequence 1: ['onion']\n",
            "Sequence 2: ['two', 'fry', 'boil', 'five', 'boil', 'steak']\n",
            "Sequence 3: ['cut', 'with', 'H', 'clean', 'cut', 'chicken', 'and', 'pork']\n",
            "Sequence 4: ['potato']\n",
            "Sequence 5: ['steak', 'and', 'steak']\n",
            "Sequence 6: ['onion', 'and', 'cut', 'one', 'tomato']\n",
            "Sequence 7: ['cut', 'cut', 'pork']\n",
            "Sequence 8: ['potato']\n",
            "Sequence 9: ['tomato']\n",
            "Sequence 10: ['steak']\n",
            "Sequence 11: ['clean', 'with', 'H', 'clean', 'onion']\n",
            "Sequence 12: ['tomato']\n",
            "Sequence 13: ['cut', 'pork', 'and', 'two', 'tomato']\n",
            "Sequence 14: ['tomato']\n",
            "Sequence 15: ['tomato']\n",
            "Sequence 16: ['potato', 'after', 'steak']\n",
            "Sequence 17: ['potato']\n",
            "Sequence 18: ['fry', 'with', 'H', 'potato']\n",
            "Sequence 19: ['five', 'tomato']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kfCVBaJwOip4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}